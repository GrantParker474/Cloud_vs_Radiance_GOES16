{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.measure  \n",
    "from skimage.metrics import mean_squared_error \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.ndimage.interpolation as interp\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as metrics\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions \n",
    "\n",
    "#downsamples image to specified size using specified method\n",
    "def downsampleIMG(img1, size, method):\n",
    "    size1 = int(img1.shape[0])\n",
    "    size2 = size\n",
    "\n",
    "    factor = int(size1/size2)\n",
    "\n",
    "    if (method == 'max'):\n",
    "        img1_reduced = skimage.measure.block_reduce(img1, (factor,factor), np.max)\n",
    "    \n",
    "    if (method == 'mean'):\n",
    "        img1_reduced = skimage.measure.block_reduce(img1, (factor,factor), np.mean)\n",
    "\n",
    "    print(f'The new size of the image is {img1_reduced.shape}')\n",
    "\n",
    "    return img1_reduced\n",
    "\n",
    "#upsamples image to specified size using specified method (we used \"nearest\" for nearest neighbors )\n",
    "def upsampleIMG(img, size, pickMode):\n",
    "    factor = size / img.shape[0]\n",
    "    newImg = interp.zoom(input = img, zoom = factor, mode = pickMode, prefilter = False)\n",
    "    print(f'The new size of the image is {newImg.shape}')\n",
    "    return newImg\n",
    "\n",
    "#normalizes a property between 0 and 1 \n",
    "def min_max_norm(X):\n",
    "    \n",
    "    return (X - np.nanmin(X)) / (np.nanmax(X) - np.nanmin(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reading in the data \n",
    "pressure = h5py.File('Data/pressure.mat')\n",
    "pressure.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function \n",
    "\n",
    "\n",
    "def testDay(dataset):\n",
    "#returns a 500,000 sample of pixels in specified dataset. Columns include COD,CTT,Pressure, SZA,LZA,ln(cod), ln(cod)*sza, lat, lon, Rad (Radiance).    \n",
    "    \n",
    "    data = h5py.File(f'Data/{dataset}', 'r')\n",
    "    pressData = h5py.File('Data/pressure.mat')\n",
    "    \n",
    "    print(data.keys())\n",
    "    \n",
    "    \n",
    "    cod = np.transpose(data['cod'][()])\n",
    "    ctt = np.transpose(data['ctt'][()])\n",
    "    sza = data['sza'][()]\n",
    "    Rad = data['Rad'][()]\n",
    "    lza = data['lza'][()]\n",
    "    \n",
    "    if dataset == \"04JAN2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure04JAN'][()])\n",
    "    elif dataset == \"05JAN2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure05JAN'][()])\n",
    "    elif dataset == \"06JAN2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure06JAN'][()])\n",
    "    elif dataset == \"04MAR2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure04MAR'][()])\n",
    "    elif dataset == \"05MAR2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure05MAR'][()])\n",
    "    elif dataset == \"03MAR2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure03MAR'][()])\n",
    "    elif dataset == \"04JULY2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure04JUL'][()])\n",
    "    elif dataset == \"05JULY2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure05JUL'][()])\n",
    "    elif dataset == \"06JULY2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure06JUL'][()])\n",
    "    elif dataset == \"04MAY2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure04MAY'][()])\n",
    "    elif dataset == \"05MAY2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure05MAY'][()])    \n",
    "    elif dataset == \"06MAY2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure06MAY'][()])\n",
    "    elif dataset == \"04SEP2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure04SEP'][()])\n",
    "    elif dataset == \"05SEP2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure05SEP'][()])\n",
    "    elif dataset == \"06SEP2020.mat\":\n",
    "        print(dataset[0:4])\n",
    "        pressure = np.transpose(pressData['pressure06SEP'][()])\n",
    "    \n",
    "    \n",
    "    print(\"Variables read in correctly\")\n",
    "    \n",
    "    #downsampling and upsampling \n",
    "    size = 10848\n",
    "\n",
    "    #downsamples\n",
    "    sza_ds = downsampleIMG(sza, size, 'max')\n",
    "    Rad_ds = downsampleIMG(Rad, size, 'max')\n",
    "    lza_ds = downsampleIMG(lza, size, 'max')\n",
    "\n",
    "    #upsamples \n",
    "    cod_us = upsampleIMG(cod, size, 'nearest')\n",
    "    ctt_us = upsampleIMG(ctt, size, 'nearest')\n",
    "    pressure_us = upsampleIMG(pressure, size, 'nearest')\n",
    "    \n",
    "    print(\"variables correctly sized\")\n",
    "    \n",
    "    #normalize the variables now \n",
    "\n",
    "    cod_n = min_max_norm(cod_us)\n",
    "    ctt_n = min_max_norm(ctt_us)\n",
    "    sza_n = min_max_norm(sza_ds)\n",
    "    lza_n = min_max_norm(lza_ds)\n",
    "    Rad_n = min_max_norm(Rad_ds)\n",
    "    press_n = min_max_norm(pressure_us)\n",
    "\n",
    "    \n",
    "    print(\"Variables correctly normalized\")\n",
    "    \n",
    "    codStretch = cod_n.reshape(-1)\n",
    "    cttStretch = ctt_n.reshape(-1)\n",
    "    szaStretch = sza_n.reshape(-1)\n",
    "    lzaStretch = lza_n.reshape(-1)\n",
    "    RadStretch = Rad_n.reshape(-1)\n",
    "    pressStretch = press_n.reshape(-1)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['cod'] = codStretch.tolist()\n",
    "    df['ctt'] = cttStretch.tolist()\n",
    "    df['sza'] = szaStretch.tolist()\n",
    "    df['lza'] = lzaStretch.tolist()\n",
    "    df['Rad'] = RadStretch.tolist()\n",
    "    df['pressure'] = pressStretch.tolist()\n",
    "    \n",
    "    print(\"DataFrame correctly made\")\n",
    "    \n",
    "    #transformations \n",
    "    df_ds = df.dropna()\n",
    "    print(df_ds)\n",
    "    print(\"Shape of dataframe is \", df_ds.shape)\n",
    "    print(\"NaN's dropped\")\n",
    "    \n",
    "    latlon = scipy.io.loadmat('Data/latlon.mat')\n",
    "    lat = latlon['latPool']\n",
    "    lon = latlon['lonPool']\n",
    "    \n",
    "    latScaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    lonScaler = MinMaxScaler(feature_range=(-1, 0))\n",
    "\n",
    "    lat_s = latScaler.fit_transform(lat)\n",
    "    lon_s = lonScaler.fit_transform(lon)\n",
    "    \n",
    "    print(\"Latitude and Longitude normalized\")\n",
    "    \n",
    "    lat_s = lat_s.reshape(-1)\n",
    "    lon_s = lon_s.reshape(-1)\n",
    "\n",
    "    df_latlon = pd.DataFrame()\n",
    "\n",
    "    df_latlon['lat'] = lat_s.tolist()\n",
    "    df_latlon['lon'] = lon_s.tolist()\n",
    "\n",
    "    df_merge = df_ds.merge(df_latlon, how = \"left\", left_index = True, right_index = True)\n",
    "    \n",
    "    print(\"Dataset merged\")\n",
    "    \n",
    "    df_merge['lncod'] = np.log(df_merge[['cod']])\n",
    "    \n",
    "    df_merge[\"lncodSza\"] = df_merge[\"lncod\"]*df_merge[\"sza\"]\n",
    "    print(f'Shape of dataset is: {df_merge.shape}')\n",
    "    \n",
    "    df_date = df_merge.sample(n=500000, random_state = 42)\n",
    "    \n",
    "    #return df_date, predictions\n",
    "    return df_date\n",
    "    #return df_merge\n",
    "    \n",
    "    \n",
    "    \n",
    "def testDayNS(dataset):\n",
    "#returns dataframe of specified dataset (day), returns all records that do not include unrecorded data, includes all properties except CTT when commented (can include CTT if uncommented)   \n",
    "    \n",
    "    data = h5py.File(f'Data/{dataset}', 'r')\n",
    "    \n",
    "    print(data.keys())\n",
    "\n",
    "    cod = np.transpose(data['cod'][()])\n",
    "    #commenting out ctt for model3\n",
    "    #ctt = np.transpose(data['ctt'][()])\n",
    "    sza = data['sza'][()]\n",
    "    Rad = data['Rad'][()]\n",
    "    lza = data['lza'][()]\n",
    "    \n",
    "    #print(cod)\n",
    "    #print(Rad)\n",
    "    \n",
    "    print(\"Variables read in correctly\")\n",
    "    \n",
    "    #downsampling and upsampling \n",
    "    size = 10848\n",
    "\n",
    "    #downsamples\n",
    "    sza_ds = downsampleIMG(sza, size, 'max')\n",
    "    Rad_ds = downsampleIMG(Rad, size, 'max')\n",
    "    lza_ds = downsampleIMG(lza, size, 'max')\n",
    "\n",
    "    #upsamples \n",
    "    cod_us = upsampleIMG(cod, size, 'nearest')\n",
    "    #ctt_us = upsampleIMG(ctt, size, 'nearest')\n",
    "    \n",
    "    print(\"variables correctly sized\")\n",
    "    \n",
    "    #normalize the variables now \n",
    "\n",
    "    cod_n = min_max_norm(cod_us)\n",
    "    #ctt_n = min_max_norm(ctt_us)\n",
    "    sza_n = min_max_norm(sza_ds)\n",
    "    lza_n = min_max_norm(lza_ds)\n",
    "    Rad_n = min_max_norm(Rad_ds)\n",
    "    \n",
    "    print(\"Variables correctly normalized\")\n",
    "    \n",
    "    codStretch = cod_n.reshape(-1)\n",
    "    #cttStretch = ctt_n.reshape(-1)\n",
    "    szaStretch = sza_n.reshape(-1)\n",
    "    lzaStretch = lza_n.reshape(-1)\n",
    "    RadStretch = Rad_n.reshape(-1)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['cod'] = codStretch.tolist()\n",
    "    #df['ctt'] = cttStretch.tolist()\n",
    "    df['sza'] = szaStretch.tolist()\n",
    "    df['lza'] = lzaStretch.tolist()\n",
    "    df['Rad'] = RadStretch.tolist()\n",
    "    \n",
    "    print(\"DataFrame correctly made\")\n",
    "    \n",
    "    #transformations \n",
    "    df_ds = df.dropna()\n",
    "    print(df_ds)\n",
    "    print(\"Shape of dataframe is \", df_ds.shape)\n",
    "    print(\"NaN's dropped\")\n",
    "    \n",
    "    latlon = scipy.io.loadmat('Data/latlon.mat')\n",
    "    lat = latlon['latPool']\n",
    "    lon = latlon['lonPool']\n",
    "    \n",
    "    latScaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    lonScaler = MinMaxScaler(feature_range=(-1, 0)) \n",
    "\n",
    "    lat_s = latScaler.fit_transform(lat)\n",
    "    lon_s = lonScaler.fit_transform(lon)\n",
    "    \n",
    "    print(\"Latitude and Longitude normalized\")\n",
    "    \n",
    "    lat_s = lat_s.reshape(-1)\n",
    "    lon_s = lon_s.reshape(-1)\n",
    "\n",
    "    df_latlon = pd.DataFrame()\n",
    "\n",
    "    df_latlon['lat'] = lat_s.tolist()\n",
    "    df_latlon['lon'] = lon_s.tolist()\n",
    "\n",
    "    df_merge = df_ds.merge(df_latlon, how = \"left\", left_index = True, right_index = True)\n",
    "    \n",
    "    print(\"Dataset merged\")\n",
    "    \n",
    "    df_merge['lncod'] = np.log(df_merge[['cod']])\n",
    "    \n",
    "    df_merge[\"lncodSza\"] = df_merge[\"lncod\"]*df_merge[\"sza\"]\n",
    "\n",
    "    return df_merge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fullSet(dataset):\n",
    "#returns full dataset as a dataframe, includes unrecorded data, and includes all original properties (COD,CTT, SZA, LZA, Rad)    \n",
    "    data = h5py.File(f'Data/{dataset}', 'r')\n",
    "    \n",
    "    print(data.keys())\n",
    "    \n",
    "    cod = np.transpose(data['cod'][()])\n",
    "    ctt = np.transpose(data['ctt'][()])\n",
    "    sza = data['sza'][()]\n",
    "    Rad = data['Rad'][()]\n",
    "    lza = data['lza'][()]\n",
    "    \n",
    "    \n",
    "    print(\"Variables read in correctly\")\n",
    "    \n",
    "    #downsampling and upsampling \n",
    "    size = 10848\n",
    "\n",
    "    #downsamples\n",
    "    sza_ds = downsampleIMG(sza, size, 'max')\n",
    "    Rad_ds = downsampleIMG(Rad, size, 'max')\n",
    "    lza_ds = downsampleIMG(lza, size, 'max')\n",
    "\n",
    "    #upsamples \n",
    "    cod_us = upsampleIMG(cod, size, 'nearest')\n",
    "    ctt_us = upsampleIMG(ctt, size, 'nearest')\n",
    "    \n",
    "    print(\"variables correctly sized\")\n",
    "    \n",
    "    #normalize the variables now \n",
    "\n",
    "    cod_n = min_max_norm(cod_us)\n",
    "    ctt_n = min_max_norm(ctt_us)\n",
    "    sza_n = min_max_norm(sza_ds)\n",
    "    lza_n = min_max_norm(lza_ds)\n",
    "    Rad_n = min_max_norm(Rad_ds)\n",
    "    \n",
    "    \n",
    "    print(\"Variables correctly normalized\")\n",
    "    \n",
    "    codStretch = cod_n.reshape(-1)\n",
    "    cttStretch = ctt_n.reshape(-1)\n",
    "    szaStretch = sza_n.reshape(-1)\n",
    "    lzaStretch = lza_n.reshape(-1)\n",
    "    RadStretch = Rad_n.reshape(-1)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df['cod'] = codStretch.tolist()\n",
    "    df['ctt'] = cttStretch.tolist()\n",
    "    df['sza'] = szaStretch.tolist()\n",
    "    df['lza'] = lzaStretch.tolist()\n",
    "    df['Rad'] = RadStretch.tolist()\n",
    "    \n",
    "    print(\"DataFrame correctly made\")\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04MAR2020= testDay('04MAR2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04MAR2020[\"Month\"] = \"March\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04JAN2020= testDay('04JAN2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04JAN2020[\"Month\"] = \"January\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05JAN2020= testDay('05JAN2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05JAN2020[\"Month\"] = \"January\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df06JAN2020 = testDay('06JAN2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df06JAN2020[\"Month\"] = \"January\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df03MAR2020 = testDay('03MAR2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df03MAR2020[\"Month\"] = \"March\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05MAR2020 = testDay('05MAR2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05MAR2020[\"Month\"] = \"March\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04MAY2020 = testDay('04MAY2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04MAY2020[\"Month\"] = \"May\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05MAY2020 = testDay('05MAY2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05MAY2020[\"Month\"] = \"May\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df05MayTestShape = testDay('05MAY2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df06MAY2020 = testDay('06MAY2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df06MAY2020[\"Month\"] = \"May\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding in both july and september \n",
    "df04JUL2020 = testDay('04JULY2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04JUL2020[\"Month\"] = \"July\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05JUL2020 = testDay('05JULY2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05JUL2020[\"Month\"] = \"July\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df06JUL2020 = testDay('06JULY2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df06JUL2020[\"Month\"] = \"July\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04SEP2020 = testDay('04SEP2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df04SEP2020[\"Month\"] = \"September\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05SEP2020 = testDay('05SEP2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05SEP2020[\"Month\"] = \"September\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df06SEP2020 = testDay('06SEP2020.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df06SEP2020[\"Month\"] = \"September\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging all 500,000 samples into one dataset \n",
    "df2020_merge= pd.concat([df04JAN2020 , df05JAN2020, df06JAN2020, df03MAR2020, df04MAY2020, df05MAY2020, df04MAY2020, df05MAY2020, df06MAY2020, df04JUL2020, df05JUL2020, df06JUL2020, df04SEP2020, df05SEP2020, df06SEP2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020_final = pd.get_dummies(data = df2020_merge, columns = [\"Month\"], prefix = \"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dropping 0 values for Rad\n",
    "df2020_finalw0 = df2020_final.loc[df2020_final[\"Rad\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2020_finalw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#correlatin matrix \n",
    "df2020_finalw0NoMonth = df2020_finalw0.drop([\"month_January\", \"month_July\", \"month_March\", \"month_May\", \"month_September\"], axis = 1)\n",
    "\n",
    "corr_matrix = df2020_finalw0NoMonth.corr()\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression with all variables except month \n",
    "smf.ols(formula='Rad ~ cod + ctt + sza + lza + lat + lon + pressure', data=df2020_finalw0).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model 1 Creation\n",
    "model1X = df2020_finalw0[[\"cod\", \"ctt\", \"lza\", \"sza\",\"lat\", \"lon\", \"pressure\"]]\n",
    "model1Y = df2020_finalw0[['Rad']]\n",
    "\n",
    "model1 = LinearRegression().fit(model1X, model1Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model1 scores \n",
    "\n",
    "print(\"R^2 = \", model1.score(model1X, model1Y))\n",
    "      \n",
    "model1pred = model1.predict(model1X)\n",
    "\n",
    "print(\"MAE = \", metrics.mean_absolute_error(model1Y, model1pred))\n",
    "print(f\"The RMSE is {np.sqrt(metrics.mean_squared_error(model1Y, model1pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#variance inflation factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# the independent variables set\n",
    "X2 = df2020_final[['cod', 'ctt', 'sza','lza','lat', 'lon', 'pressure']]\n",
    "  \n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X2.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X2.values, i)\n",
    "                          for i in range(len(X2.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model 2: Transformed model by taking ln(cod) and adding interaction term ln(cod)*sza\n",
    "smf.ols(formula='Rad ~ lncod + lncodSza + ctt + sza + lza + lat + lon + pressure', data=df2020_finalw0).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model 2 Creation\n",
    "model2X = df2020_finalw0[[\"lncod\", \"lncodSza\", \"ctt\", \"lza\", \"sza\",\"lat\", \"lon\"]]\n",
    "model2Y = df2020_finalw0[['Rad']]\n",
    "\n",
    "model2 = LinearRegression().fit(model2X, model2Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model2 Scores\n",
    "print(\"R^2 = \", model2.score(model2X, model2Y))\n",
    "      \n",
    "model2pred = model2.predict(model2X)\n",
    "\n",
    "print(\"MAE = \", metrics.mean_absolute_error(model2Y, model2pred))\n",
    "print(f\"The RMSE is {np.sqrt(metrics.mean_squared_error(model2Y, model2pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model3 -- final\n",
    "smf.ols(formula='Rad ~ lncod + lncodSza + sza', data=df2020_finalw0).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model3 Creation \n",
    "\n",
    "model3X = df2020_finalw0[[\"lncod\", \"lncodSza\", \"sza\"]]\n",
    "model3Y = df2020_finalw0[['Rad']]\n",
    "\n",
    "model3 = LinearRegression().fit(model3X, model3Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model3 Scores \n",
    "print(\"R^2 = \", model3.score(model3X, model3Y))\n",
    "      \n",
    "model3pred = model3.predict(model3X)\n",
    "\n",
    "print(\"MAE = \", metrics.mean_absolute_error(model3Y, model3pred))\n",
    "print(f\"The RMSE is {np.sqrt(metrics.mean_squared_error(model3Y, model3pred))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance inflation factor\n",
    "\n",
    "\n",
    "# the independent variables set\n",
    "Xcov = df2020_finalw0[['sza', 'lncodSza']]\n",
    "  \n",
    "# VIF dataframe\n",
    "vif_dataCov = pd.DataFrame()\n",
    "vif_dataCov[\"feature\"] = Xcov.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_dataCov[\"VIF\"] = [variance_inflation_factor(Xcov.values, i)\n",
    "                          for i in range(len(Xcov.columns))]\n",
    "  \n",
    "print(vif_dataCov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training and test sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(model3X, model3Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model 3 performance on big dataset\n",
    "model3.score(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model 3 cross validation \n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "linear = LinearRegression()\n",
    "cv_results = cross_validate(linear, X, Y, cv = 5)\n",
    "sorted(cv_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results of cross validation\n",
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of the response ... training set (merged samples from 15 datasets in 2020) (Rad != 0)\n",
    "df2020_finalwo0['Rad'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR NOW 05FEBNIGHT SKIP NEXT FEW LINES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the Rad values and predictions and residuals\n",
    "\n",
    "def predAndResid(dataset, model20201):\n",
    "    df = testDayNS(dataset)\n",
    "    print(\"dataset read in -- ready to predict\")\n",
    "    #uncomment to use model 2 (transformed model) variables \n",
    "    #Xtestvar = df[[\"lncod\", \"lncodSza\", \"ctt\", \"sza\", \"lza\", \"lat\", \"lon\"]]\n",
    "    #using model3\n",
    "    Xtestvar = df[[\"lncod\", \"lncodSza\", \"sza\"]]\n",
    "    Ytestvar= df[['Rad']]\n",
    "    \n",
    "    #getting R^2, MAE, RMSE\n",
    "    score = model20201.score(Xtestvar, Ytestvar) #be careful using global variables in a function... will want to change this later....\n",
    "    print(\"The R^2 = \", score)\n",
    "    predictions = model20201.predict(Xtestvar)\n",
    "    print(\"MAE = \", metrics.mean_absolute_error(Ytestvar, predictions))\n",
    "    print(f\"The RMSE is {np.sqrt(metrics.mean_squared_error(Ytestvar, predictions))}\")\n",
    "    \n",
    "    predDf = pd.DataFrame()\n",
    "    \n",
    "    indx = np.array(df.index.tolist())\n",
    "    indx = indx.reshape(indx.shape[0], 1)\n",
    "    \n",
    "    predDf[[\"prediction\"]] = predictions\n",
    "    predDf[['indx']] = indx\n",
    "    \n",
    "    dfFull = fullSet(dataset)\n",
    "    \n",
    "    print(\"Full dataset created\")\n",
    "    \n",
    "    dfHeatMap = dfFull.merge(predDf, how = \"left\", left_index = True, right_on = predDf[\"indx\"])\n",
    "    dfHeatMap.set_index('key_0')\n",
    "    print(\"Predictions Filled\")\n",
    "    \n",
    "    #getting the residuals \n",
    "    resid = np.subtract(dfHeatMap[['Rad']], dfHeatMap[['prediction']]).values\n",
    "    print(\"Residuals created\")\n",
    "    RadVal = dfHeatMap[['Rad']].values.reshape(10848,10848)\n",
    "    print(\"Rad values obtained\")\n",
    "    RadPred = dfHeatMap[['prediction']].values.reshape(10848,10848)\n",
    "    resid = resid.reshape(10848, 10848)\n",
    "    #absolute value of the residuals \n",
    "    residAbs = abs(resid)\n",
    "    \n",
    "    return RadVal, RadPred, residAbs, dfHeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RadVal05MAY are the Rad values, RadPred05May are the predictions, residAbs05May are the errors, and MAY05SET is the full dataset with all variables \n",
    "RadVal05MAY, RadPred05MAY, residAbs05MAY, MAY05set = predAndResid(\"05MAY2020.mat\", model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAY05set[\"error\"] = residAbs05MAY.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAY05set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#May 5th 2020 error by Rad threshold \n",
    "for i in np.arange(0, 1, .1):\n",
    "    print(f'Threshold {i} - {i + .1}: {np.mean(MAY05set.loc[(MAY05set[\"Rad\"] >= i) & (MAY05set[\"Rad\"] <= i + .1) & (MAY05set[\"Rad\"].isna() == False) & (MAY05set[\"error\"].isna() == False)][\"error\"])}, count : {MAY05set.loc[(MAY05set[\"Rad\"] >= i) & (MAY05set[\"Rad\"] <= i + .1) & (MAY05set[\"Rad\"].isna() == False) & (MAY05set[\"error\"].isna() == False)].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#January 5th Rad values, predictions, errors, and total dataset \n",
    "RadVal05JAN, RadPred05JAN, residAbs05JAN, JAN05set = predAndResid(\"05JAN2020.mat\", model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RadVal05JAN2 = RadVal05JAN\n",
    "RadVal05JAN2[RadVal05JAN2 == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating Rad Truth map, Prediction map, and error map \n",
    "f2may, (ax3may, ax4may, ax2may) = plt.subplots(1,3, figsize = (15,5))\n",
    "masked_array2may = np.ma.array(residAbs05JAN, mask=np.isnan(residAbs05JAN))\n",
    "cmap2may = plt.cm.Reds\n",
    "cmap2may.set_bad('grey',1.)\n",
    "cac2may = ax2may.imshow(masked_array2may, interpolation='none', cmap=cmap2may, vmin = 0, vmax = .2)\n",
    "ax2may.set_title(\"05JAN2020 Error Map\")\n",
    "f2may.colorbar(cac2may, ax=ax2may)\n",
    "\n",
    "cac4may = ax4may.imshow(RadPred05JAN, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax4may.set_title(\"05JAN2020 Rad Prediction\")\n",
    "f2may.colorbar(cac4may, ax=ax4may)\n",
    "\n",
    "cac3may = ax3may.imshow(RadVal05JAN2, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax3may.set_title(\"05JAN2020 Rad\")\n",
    "f2may.colorbar(cac3may, ax=ax3may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JAN05set[\"error\"] = residAbs05JAN.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#January 5th error by Rad threshold \n",
    "for i in np.arange(0, 1, .1):\n",
    "    print(f'Threshold {i} - {i + .1}: {np.mean(JAN05set.loc[(JAN05set[\"Rad\"] >= i) & (JAN05set[\"Rad\"] <= i + .1) & (JAN05set[\"Rad\"].isna() == False) & (JAN05set[\"error\"].isna() == False)][\"error\"])}, count : {JAN05set.loc[(JAN05set[\"Rad\"] >= i) & (JAN05set[\"Rad\"] <= i + .1) & (JAN05set[\"Rad\"].isna() == False) & (JAN05set[\"error\"].isna() == False)].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#March 5th 2020 Rad values, predictions, errors, and total dataset \n",
    "RadVal05MAR, RadPred05MAR, residAbs05MAR, MAR05set = predAndResid(\"05MAR2020.mat\", model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RadVal05MAR2 = RadVal05MAR\n",
    "RadVal05MAR2[RadVal05MAR2 == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#March 5th 2020 Rad Truth Map, Prediction Map, and Error Map \n",
    "f2may, (ax3may, ax4may, ax2may) = plt.subplots(1,3, figsize = (15,5))\n",
    "masked_array2may = np.ma.array(residAbs05MAR, mask=np.isnan(residAbs05MAR))\n",
    "#cmap = plt.cm.jet\n",
    "#cmap2may = plt.cm.binary\n",
    "#cmap2may.set_bad('green',1.)\n",
    "cmap2may = plt.cm.Reds\n",
    "cmap2may.set_bad('grey',1.)\n",
    "cac2may = ax2may.imshow(masked_array2may, interpolation='none', cmap=cmap2may, vmin = 0, vmax = .2)\n",
    "ax2may.set_title(\"05MAR2020 Error Map\")\n",
    "f2may.colorbar(cac2may, ax=ax2may)\n",
    "\n",
    "cac4may = ax4may.imshow(RadPred05MAR, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax4may.set_title(\"05MAR2020 Rad Prediction\")\n",
    "f2may.colorbar(cac4may, ax=ax4may)\n",
    "\n",
    "cac3may = ax3may.imshow(RadVal05MAR2, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax3may.set_title(\"05MAR2020 Rad\")\n",
    "f2may.colorbar(cac3may, ax=ax3may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAR05set[\"error\"] = residAbs05MAR.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#March 5th error by Rad threshold \n",
    "for i in np.arange(0, 1, .1):\n",
    "    print(f'Threshold {i} - {i + .1}: {np.mean(MAR05set.loc[(MAR05set[\"Rad\"] >= i) & (MAR05set[\"Rad\"] <= i + .1) & (MAR05set[\"Rad\"].isna() == False) & (MAR05set[\"error\"].isna() == False)][\"error\"])}, count : {MAR05set.loc[(MAR05set[\"Rad\"] >= i) & (MAR05set[\"Rad\"] <= i + .1) & (MAR05set[\"Rad\"].isna() == False) & (MAR05set[\"error\"].isna() == False)].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#July 5th Rad values, predictions, errors, and total dataset \n",
    "RadVal05JULY, RadPred05JULY, residAbs05JULY, JULY05set = predAndResid(\"05JULY2020.mat\", model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RadVal05JULY2 = RadVal05JULY\n",
    "RadVal05JULY2[RadVal05JULY2 == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#July 5th Rad truth map, prediction map, and error map \n",
    "f2may, (ax3may, ax4may, ax2may) = plt.subplots(1,3, figsize = (15,5))\n",
    "masked_array2may = np.ma.array(residAbs05JULY, mask=np.isnan(residAbs05JULY))\n",
    "#cmap = plt.cm.jet\n",
    "#cmap2may = plt.cm.binary\n",
    "#cmap2may.set_bad('green',1.)\n",
    "cmap2may = plt.cm.Reds\n",
    "cmap2may.set_bad('grey',1.)\n",
    "cac2may = ax2may.imshow(masked_array2may, interpolation='none', cmap=cmap2may, vmin = 0, vmax = .2)\n",
    "ax2may.set_title(\"05JULY020 Error Map\")\n",
    "f2may.colorbar(cac2may, ax=ax2may)\n",
    "\n",
    "cac4may = ax4may.imshow(RadPred05JULY, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax4may.set_title(\"05JULY2020 Rad Prediction\")\n",
    "f2may.colorbar(cac4may, ax=ax4may)\n",
    "\n",
    "cac3may = ax3may.imshow(RadVal05JULY2, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax3may.set_title(\"05JULY Rad\")\n",
    "f2may.colorbar(cac3may, ax=ax3may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JULY05set[\"error\"] = residAbs05JULY.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#July 5th error by Rad threshold \n",
    "for i in np.arange(0, 1, .1):\n",
    "    print(f'Threshold {i} - {i + .1}: {np.mean(JULY05set.loc[(JULY05set[\"Rad\"] >= i) & (JULY05set[\"Rad\"] <= i + .1) & (JULY05set[\"Rad\"].isna() == False) & (JULY05set[\"error\"].isna() == False)][\"error\"])}, count : {JULY05set.loc[(JULY05set[\"Rad\"] >= i) & (JULY05set[\"Rad\"] <= i + .1) & (JULY05set[\"Rad\"].isna() == False) & (JULY05set[\"error\"].isna() == False)].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#September 5th Rad values, predictions, errors, and total dataset\n",
    "RadVal05SEP, RadPred05EP, residAbs05SEP, SEP05set = predAndResid(\"05SEP2020.mat\", model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RadVal05SEP2 = RadVal05SEP\n",
    "RadVal05SEP2[RadVal05SEP2 == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#September 5th 2020 truth Rad, prediction map, and error map \n",
    "\n",
    "f2may, (ax3may, ax4may, ax2may) = plt.subplots(1,3, figsize = (15,5))\n",
    "masked_array2may = np.ma.array(residAbs05SEP, mask=np.isnan(residAbs05SEP))\n",
    "#cmap = plt.cm.jet\n",
    "#cmap2may = plt.cm.binary\n",
    "#cmap2may.set_bad('green',1.)\n",
    "cmap2may = plt.cm.Reds\n",
    "cmap2may.set_bad('grey',1.)\n",
    "cac2may = ax2may.imshow(masked_array2may, interpolation='none', cmap=cmap2may, vmin = 0, vmax = .2)\n",
    "ax2may.set_title(\"05SEP020 Error Map\")\n",
    "f2may.colorbar(cac2may, ax=ax2may)\n",
    "\n",
    "cac4may = ax4may.imshow(RadPred05EP, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax4may.set_title(\"05SEP2020 Rad Prediction\")\n",
    "f2may.colorbar(cac4may, ax=ax4may)\n",
    "\n",
    "cac3may = ax3may.imshow(RadVal05SEP2, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax3may.set_title(\"05SEP Rad\")\n",
    "f2may.colorbar(cac3may, ax=ax3may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEP05set[\"error\"] = residAbs05SEP.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#September 5th error by Rad threshold\n",
    "\n",
    "for i in np.arange(0, 1, .1):\n",
    "    print(f'Threshold {i} - {i + .1}: {np.mean(SEP05set.loc[(SEP05set[\"Rad\"] >= i) & (SEP05set[\"Rad\"] <= i + .1) & (SEP05set[\"Rad\"].isna() == False) & (SEP05set[\"error\"].isna() == False)][\"error\"])}, count : {SEP05set.loc[(SEP05set[\"Rad\"] >= i) & (SEP05set[\"Rad\"] <= i + .1) & (SEP05set[\"Rad\"].isna() == False) & (SEP05set[\"error\"].isna() == False)].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#May 15th 2020 Rad values, predictions, errors, and total dataset \n",
    "\n",
    "RadVal15MAY, RadPred15MAY, residAbs15MAY, MAY15set = predAndResid(\"MAY152020new2.mat\", model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RadVal15MAY2 = RadVal15MAY\n",
    "RadVal15MAY2[RadVal15MAY2 == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#May 15th truth Rad, prediction map, and error map \n",
    "\n",
    "f2may, (ax3may, ax4may, ax2may) = plt.subplots(1,3, figsize = (15,5))\n",
    "masked_array2may = np.ma.array(residAbs15MAY, mask=np.isnan(residAbs15MAY))\n",
    "#cmap = plt.cm.jet\n",
    "#cmap2may = plt.cm.binary\n",
    "#cmap2may.set_bad('green',1.)\n",
    "cmap2may = plt.cm.Reds\n",
    "cmap2may.set_bad('grey',1.)\n",
    "cac2may = ax2may.imshow(masked_array2may, interpolation='none', cmap=cmap2may, vmin = 0, vmax = .2)\n",
    "ax2may.set_title(\"15MAY2020 Error Map\")\n",
    "f2may.colorbar(cac2may, ax=ax2may)\n",
    "\n",
    "cac4may = ax4may.imshow(RadPred15MAY, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax4may.set_title(\"15MAY2020 Rad Prediction\")\n",
    "f2may.colorbar(cac4may, ax=ax4may)\n",
    "\n",
    "cac3may = ax3may.imshow(RadVal15MAY2, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax3may.set_title(\"15MAY2020 Rad\")\n",
    "f2may.colorbar(cac3may, ax=ax3may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAY15set[\"error\"] = residAbs15MAY.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#May 15th error by Rad threshold \n",
    "\n",
    "for i in np.arange(0, 1, .1):\n",
    "    print(f'Threshold {i} - {i + .1}: {np.mean(MAY15set.loc[(MAY15set[\"Rad\"] >= i) & (MAY15set[\"Rad\"] <= i + .1) & (MAY15set[\"Rad\"].isna() == False) & (MAY15set[\"error\"].isna() == False)][\"error\"])}, count : {MAY15set.loc[(MAY15set[\"Rad\"] >= i) & (MAY15set[\"Rad\"] <= i + .1) & (MAY15set[\"Rad\"].isna() == False) & (MAY15set[\"error\"].isna() == False)].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#May 5th 2020 Rad, prediction, and error map \n",
    "f2may, (ax3may, ax4may, ax2may) = plt.subplots(1,3, figsize = (15,5))\n",
    "masked_array2may = np.ma.array(residAbs05MAY, mask=np.isnan(residAbs05MAY))\n",
    "#cmap = plt.cm.jet\n",
    "#cmap2may = plt.cm.binary\n",
    "#cmap2may.set_bad('green',1.)\n",
    "cmap2may = plt.cm.Reds\n",
    "cmap2may.set_bad('grey',1.)\n",
    "cac2may = ax2may.imshow(masked_array2may, interpolation='none', cmap=cmap2may, vmin = 0, vmax = .2)\n",
    "ax2may.set_title(\"05MAY2020 Error Map\")\n",
    "f2may.colorbar(cac2may, ax=ax2may)\n",
    "\n",
    "cac4may = ax4may.imshow(RadPred05MAY, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax4may.set_title(\"05MAY2020 Rad Prediction\")\n",
    "f2may.colorbar(cac4may, ax=ax4may)\n",
    "\n",
    "cac3may = ax3may.imshow(RadVal05MAY, interpolation='none', vmin = 0, vmax = 1)  #could do interpolation none....\n",
    "ax3may.set_title(\"05MAY2020 Rad\")\n",
    "f2may.colorbar(cac3may, ax=ax3may)"
   ]
  }
 ],
 "metadata": {
  "@deathbeds/jupyterlab-fonts": {
   "styles": {
    ":root": {
     "--jp-code-font-size": "12px"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
